import pandas as pd
import numpy as np
import random
from datetime import datetime, timedelta
import json
import os
import uuid
from sklearn.preprocessing import LabelEncoder

class CTUConnectDataGenerator:
    """T·∫°o dataset m·∫´u cho h·ªá th·ªëng CTU Connect d·ª±a tr√™n c·∫•u tr√∫c th·ª±c t·∫ø"""

    def __init__(self, seed=42):
        random.seed(seed)
        np.random.seed(seed)

        # Danh s√°ch khoa th·ª±c t·∫ø t·∫°i CTU
        self.faculties = [
            {'code': 'CNTT', 'name': 'Tr∆∞·ªùng C√¥ng ngh·ªá Th√¥ng tin v√† Truy·ªÅn th√¥ng', 'college': 'CTU'},
            {'code': 'NN', 'name': 'Khoa N√¥ng nghi·ªáp', 'college': 'CTU'},
            {'code': 'KYTH', 'name': 'Khoa K·ªπ thu·∫≠t', 'college': 'CTU'},
            {'code': 'KT', 'name': 'Khoa Kinh t·∫ø', 'college': 'CTU'},
            {'code': 'SP', 'name': 'Khoa S∆∞ ph·∫°m', 'college': 'CTU'},
            {'code': 'YD', 'name': 'Khoa Y D∆∞·ª£c', 'college': 'CTU'},
            {'code': 'KHTN', 'name': 'Khoa Khoa h·ªçc T·ª± nhi√™n', 'college': 'CTU'},
            {'code': 'KHXHNV', 'name': 'Khoa Khoa h·ªçc X√£ h·ªôi v√† Nh√¢n vƒÉn', 'college': 'CTU'},
            {'code': 'LUAT', 'name': 'Khoa Lu·∫≠t', 'college': 'CTU'},
            {'code': 'NONE', 'name': 'Kh√¥ng li√™n quan h·ªçc thu·∫≠t', 'college': 'CTU'}
        ]

        # Danh s√°ch ng√†nh h·ªçc theo t·ª´ng khoa
        self.majors_by_faculty = {
            'CNTT': [
                {'code': 'CNPM01', 'name': 'C√¥ng ngh·ªá Ph·∫ßn m·ªÅm'},
                {'code': 'KTPM01', 'name': 'K·ªπ thu·∫≠t Ph·∫ßn m·ªÅm'},
                {'code': 'HTTT01', 'name': 'H·ªá th·ªëng Th√¥ng tin'},
                {'code': 'KHMT01', 'name': 'Khoa h·ªçc M√°y t√≠nh'},
                {'code': 'MMT01', 'name': 'M·∫°ng m√°y t√≠nh v√† Truy·ªÅn th√¥ng d·ªØ li·ªáu'},
                {'code': 'ATT01', 'name': 'An to√†n Th√¥ng tin'}
            ],
            'NN': [
                {'code': 'AGRO', 'name': 'N√¥ng h·ªçc'},
                {'code': 'PLANT', 'name': 'B·∫£o v·ªá Th·ª±c v·∫≠t'},
                {'code': 'SOIL', 'name': 'Khoa h·ªçc ƒê·∫•t'},
                {'code': 'CROP', 'name': 'Khoa h·ªçc C√¢y tr·ªìng'}
            ],
            'KYTH': [
                {'code': 'KTXD01', 'name': 'K·ªπ thu·∫≠t X√¢y d·ª±ng'},
                {'code': 'KTCK01', 'name': 'K·ªπ thu·∫≠t C∆° kh√≠'},
                {'code': 'ROBOT01', 'name': 'Robot v√† Tr√≠ tu·ªá nh√¢n t·∫°o'}
            ],
            'KT': [
                {'code': 'KT01', 'name': 'Kinh t·∫ø h·ªçc'},
                {'code': 'MKT01', 'name': 'Marketing'},
                {'code': 'QTKD01', 'name': 'Qu·∫£n tr·ªã Kinh doanh'},
                {'code': 'TC01', 'name': 'T√†i ch√≠nh - Ng√¢n h√†ng'}
            ],
            'SP': [
                {'code': 'MATH_EDU', 'name': 'S∆∞ ph·∫°m To√°n'},
                {'code': 'PHYS_EDU', 'name': 'S∆∞ ph·∫°m V·∫≠t l√Ω'},
                {'code': 'CHEM_EDU', 'name': 'S∆∞ ph·∫°m H√≥a h·ªçc'},
                {'code': 'BIO_EDU', 'name': 'S∆∞ ph·∫°m Sinh h·ªçc'}
            ],
            'NONE': []
        }

        # Vai tr√≤ ng∆∞·ªùi d√πng (b·ªè RESEARCHER)
        self.roles = ['STUDENT', 'LECTURER', 'STAFF', 'ADMIN']

        # Tr√¨nh ƒë·ªô h·ªçc v·∫•n
        self.degrees = [
            {'code': 'CU_NHAN', 'name': 'C·ª≠ nh√¢n'},
            {'code': 'THAC_SI', 'name': 'Th·∫°c sƒ©'},
            {'code': 'TIEN_SI', 'name': 'Ti·∫øn sƒ©'},
            {'code': 'PHO_GIAO_SU', 'name': 'Ph√≥ Gi√°o s∆∞'},
            {'code': 'GIAO_SU', 'name': 'Gi√°o s∆∞'},
            {'code': 'KHAC', 'name': 'Kh√°c'}
        ]

        # Ch·ª©c v·ª•
        self.positions = [
            {'code': 'STUDENT', 'name': 'Sinh vi√™n'},
            {'code': 'GIANG_VIEN', 'name': 'Gi·∫£ng vi√™n'},
            {'code': 'GIANG_VIEN_CHINH', 'name': 'Gi·∫£ng vi√™n ch√≠nh'},
            {'code': 'PHO_GIAO_SU', 'name': 'Ph√≥ Gi√°o s∆∞'},
            {'code': 'GIAO_SU', 'name': 'Gi√°o s∆∞'},
            {'code': 'CAN_BO', 'name': 'C√°n b·ªô'},
            {'code': 'TRO_LY', 'name': 'Tr·ª£ l√Ω'}
        ]

        # Kh√≥a h·ªçc
        self.batches = [
            {'id': f'K{year}', 'year': year}
            for year in range(2021, 2026)
        ]

        # Gi·ªõi t√≠nh
        self.genders = [
            {'id': 'M', 'name': 'Nam'},
            {'id': 'F', 'name': 'N·ªØ'}
        ]

        # Danh m·ª•c b√†i vi·∫øt m·ªõi
        self.post_categories = [
            'research', 'teaching', 'aquaculture', 'technology', 'climate',
            'student', 'events', 'discussion', 'other'
        ]

        # Ch·∫ø ƒë·ªô ri√™ng t∆∞
        self.privacy_settings = ['PUBLIC', 'FRIENDS', 'FACULTY', 'PRIVATE']

        # Content templates cho t·ª´ng category
        self.content_templates = {
            'research': [
                "Nghi√™n c·ª©u m·ªõi v·ªÅ ·ª©ng d·ª•ng AI trong n√¥ng nghi·ªáp th√¥ng minh t·∫°i v√πng ƒêBSCL.",
                "K·∫øt qu·∫£ nghi√™n c·ª©u v·ªÅ t√°c ƒë·ªông c·ªßa bi·∫øn ƒë·ªïi kh√≠ h·∫≠u ƒë·∫øn nƒÉng su·∫•t l√∫a.",
                "Ph√°t tri·ªÉn h·ªá th·ªëng gi√°m s√°t ch·∫•t l∆∞·ª£ng n∆∞·ªõc b·∫±ng IoT.",
                "Nghi√™n c·ª©u blockchain trong qu·∫£n l√Ω chu·ªói cung ·ª©ng n√¥ng s·∫£n."
            ],
            'teaching': [
                "Ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y t√≠ch c·ª±c trong m√¥n K·ªπ thu·∫≠t Ph·∫ßn m·ªÅm.",
                "Chia s·∫ª t√†i li·ªáu h·ªçc t·∫≠p cho sinh vi√™n ng√†nh Kinh t·∫ø.",
                "Kinh nghi·ªám t·ªï ch·ª©c l·ªõp h·ªçc tr·ª±c tuy·∫øn hi·ªáu qu·∫£.",
                "·ª®ng d·ª•ng c√¥ng ngh·ªá th·ª±c t·∫ø ·∫£o trong gi·∫£ng d·∫°y."
            ],
            'aquaculture': [
                "K·ªπ thu·∫≠t nu√¥i t√¥m b·ªÅn v·ªØng t·∫°i ƒêBSCL.",
                "Nghi√™n c·ª©u c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng n∆∞·ªõc trong nu√¥i tr·ªìng th·ªßy s·∫£n.",
                "·ª®ng d·ª•ng c·∫£m bi·∫øn IoT trong qu·∫£n l√Ω ao nu√¥i t√¥m.",
                "Ph∆∞∆°ng ph√°p m·ªõi trong ph√≤ng ch·ªëng b·ªánh t√¥m."
            ],
            'technology': [
                "·ª®ng d·ª•ng AI trong t·ª± ƒë·ªông h√≥a n√¥ng nghi·ªáp.",
                "Gi·ªõi thi·ªáu c√¥ng ngh·ªá 5G trong gi√°o d·ª•c.",
                "Ph√°t tri·ªÉn ·ª©ng d·ª•ng di ƒë·ªông cho sinh vi√™n CTU.",
                "T√¨m hi·ªÉu v·ªÅ robot trong s·∫£n xu·∫•t c√¥ng nghi·ªáp."
            ],
            'climate': [
                "T√°c ƒë·ªông c·ªßa bi·∫øn ƒë·ªïi kh√≠ h·∫≠u ƒë·∫øn n√¥ng nghi·ªáp ƒêBSCL.",
                "Gi·∫£i ph√°p gi·∫£m ph√°t th·∫£i kh√≠ nh√† k√≠nh trong nu√¥i tr·ªìng.",
                "Nghi√™n c·ª©u v·ªÅ d·ª± b√°o th·ªùi ti·∫øt ·ª©ng d·ª•ng AI.",
                "Chia s·∫ª kinh nghi·ªám th√≠ch ·ª©ng v·ªõi m·ª±c n∆∞·ªõc bi·ªÉn d√¢ng."
            ],
            'student': [
                "C√¢u chuy·ªán sinh vi√™n CTU v∆∞·ª£t kh√≥ ƒë·∫°t h·ªçc b·ªïng qu·ªëc t·∫ø.",
                "H√†nh tr√¨nh kh·ªüi nghi·ªáp c·ªßa sinh vi√™n ng√†nh C√¥ng ngh·ªá Th√¥ng tin.",
                "Tips thi cu·ªëi k·ª≥ hi·ªáu qu·∫£ cho sinh vi√™n.",
                "Chia s·∫ª kinh nghi·ªám tham gia c√¢u l·∫°c b·ªô CTU."
            ],
            'events': [
                "S·ª± ki·ªán giao l∆∞u vƒÉn h√≥a sinh vi√™n CTU 2025.",
                "H·ªôi th·∫£o c√¥ng ngh·ªá th√¥ng tin t·∫°i CTU.",
                "Ng√†y h·ªôi vi·ªác l√†m cho sinh vi√™n ng√†nh K·ªπ thu·∫≠t.",
                "Workshop k·ªπ nƒÉng m·ªÅm cho sinh vi√™n nƒÉm nh·∫•t."
            ],
            'discussion': [
                "Th·∫£o lu·∫≠n v·ªÅ vai tr√≤ c·ªßa AI trong gi√°o d·ª•c ƒë·∫°i h·ªçc.",
                "Chia s·∫ª √Ω ki·∫øn v·ªÅ c·∫£i c√°ch ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o.",
                "Trao ƒë·ªïi kinh nghi·ªám nghi√™n c·ª©u khoa h·ªçc sinh vi√™n.",
                "C√πng b√†n lu·∫≠n v·ªÅ gi·∫£i ph√°p ph√°t tri·ªÉn b·ªÅn v·ªØng ƒêBSCL."
            ],
            'other': [
                "Top 5 qu√°n c√† ph√™ l√Ω t∆∞·ªüng cho sinh vi√™n C·∫ßn Th∆°.",
                "Chia s·∫ª h√†nh tr√¨nh kh√°m ph√° mi·ªÅn T√¢y cu·ªëi tu·∫ßn.",
                "B√≠ k√≠p ch·ª•p ·∫£nh ƒë·∫πp t·∫°i ch·ª£ n·ªïi C√°i RƒÉng.",
                "C√¢u chuy·ªán vui v·ªÅ ƒë·ªùi s·ªëng sinh vi√™n CTU."
            ]
        }

    def generate_uuid(self):
        """T·∫°o UUID theo format c·ªßa h·ªá th·ªëng"""
        return str(uuid.uuid4())

    def generate_users(self, n_users=100):
        """T·∫°o d·ªØ li·ªáu users theo c·∫•u tr√∫c UserEntity th·ª±c t·∫ø"""
        users = []
        faculty_encoder = LabelEncoder()
        faculty_codes = [f['code'] for f in self.faculties]
        faculty_encoded = faculty_encoder.fit_transform(faculty_codes)

        for i in range(n_users):
            user_id = self.generate_uuid()

            # Ph√¢n b·ªë role (b·ªè RESEARCHER)
            if i < n_users * 0.7:  # 70% sinh vi√™n
                role = 'STUDENT'
            elif i < n_users * 0.9:  # 20% gi·∫£ng vi√™n
                role = 'LECTURER'
            else:  # 10% c√°n b·ªô/admin
                role = random.choice(['STAFF', 'ADMIN'])

            # T·∫°o th√¥ng tin c∆° b·∫£n
            username = f"user{i+1:04d}"
            email = f"{username}@ctu.edu.vn"
            full_name = self.generate_vietnamese_name()

            # Ch·ªçn faculty v√† major
            faculty = random.choice([f for f in self.faculties if f['code'] != 'NONE'])
            major_list = self.majors_by_faculty.get(faculty['code'], [])
            major = random.choice(major_list) if major_list else None

            # Th√¥ng tin h·ªçc t·∫≠p/c√¥ng vi·ªác
            if role == 'STUDENT':
                student_id = f"B{random.randint(1900000, 2199999)}"
                staff_code = None
                batch = random.choice(self.batches)
                degree = random.choice([d for d in self.degrees if d['code'] in ['CU_NHAN', 'KHAC']])
                position = next(p for p in self.positions if p['code'] == 'STUDENT')
            else:
                student_id = None
                staff_code = f"CB{random.randint(10000, 99999)}"
                batch = None
                degree = random.choice([d for d in self.degrees if d['code'] in ['THAC_SI', 'TIEN_SI', 'PHO_GIAO_SU', 'GIAO_SU']])
                position = random.choice([p for p in self.positions if p['code'] != 'STUDENT'])

            gender = random.choice(self.genders)

            # Profile completion v√† th√¥ng tin b·ªï sung
            is_profile_completed = random.choice([True, False])
            bio = self.generate_bio(role, faculty['name']) if is_profile_completed else None
            avatar_url = f"https://example.com/avatars/{user_id}.jpg" if random.random() > 0.3 else None

            users.append({
                'id': user_id,
                'email': email,
                'username': username,
                'full_name': full_name,
                'role': role,
                'bio': bio,
                'is_profile_completed': is_profile_completed,
                'avatar_url': avatar_url,
                'background_url': None,
                'student_id': student_id,
                'staff_code': staff_code,
                'is_active': True,
                'created_at': (datetime.now() - timedelta(days=random.randint(30, 1095))).isoformat(),
                'updated_at': datetime.now().isoformat(),
                # Relations
                'faculty_code': faculty['code'],
                'faculty_name': faculty['name'],
                'major_code': major['code'] if major else None,
                'major_name': major['name'] if major else None,
                'batch_id': batch['id'] if batch else None,
                'batch_year': batch['year'] if batch else None,
                'gender_id': gender['id'],
                'gender_name': gender['name'],
                'degree_code': degree['code'],
                'degree_name': degree['name'],
                'position_code': position['code'],
                'position_name': position['name'],
                'college_name': 'ƒê·∫°i h·ªçc C·∫ßn Th∆°',
                'user_faculty_encoded': faculty_encoded[faculty_codes.index(faculty['code'])] / max(faculty_encoded)
            })

        return pd.DataFrame(users)

    def generate_vietnamese_name(self):
        """T·∫°o t√™n ti·∫øng Vi·ªát ng·∫´u nhi√™n"""
        first_names = [
            'Nguy·ªÖn', 'Tr·∫ßn', 'L√™', 'Ph·∫°m', 'Hu·ª≥nh', 'Ho√†ng', 'Phan', 'V≈©', 'V√µ', 'ƒê·∫∑ng',
            'B√πi', 'ƒê·ªó', 'H·ªì', 'Ng√¥', 'D∆∞∆°ng', 'L√Ω', 'L∆∞∆°ng', 'Tr·ªãnh', 'ƒêinh', 'T√¥'
        ]
        middle_names = ['VƒÉn', 'Th·ªã', 'H·ªØu', 'Minh', 'Thanh', 'Ho√†ng', 'Qu·ªëc', 'ƒê·ª©c', 'H·ªìng', 'Thu']
        last_names_male = [
            'Nam', 'H√πng', 'D≈©ng', 'Tu·∫•n', 'Hi·∫øu', 'Phong', 'Minh', 'Quang', 'ƒê·ª©c', 'B√¨nh',
            'Long', 'Th√†nh', 'Khang', 'H·∫£i', 'T√¢n', 'Vi·ªát', 'S∆°n', 'Khoa', 'T√πng', 'Ki√™n'
        ]
        last_names_female = [
            'Linh', 'Nga', 'H∆∞∆°ng', 'Lan', 'Mai', 'Ch√¢u', 'Th·∫£o', 'Hoa', 'Y·∫øn', 'Nhung',
            'Trang', 'Giang', 'Ph∆∞∆°ng', 'Oanh', 'Xu√¢n', 'Thu', 'H√†', 'Di·ªáu', 'Kh√°nh', 'My'
        ]
        first_name = random.choice(first_names)
        middle_name = random.choice(middle_names)
        last_name = random.choice(last_names_female if middle_name == 'Th·ªã' else last_names_male + last_names_female)
        return f"{first_name} {middle_name} {last_name}"

    def generate_bio(self, role, faculty_name):
        """T·∫°o bio ph√π h·ª£p v·ªõi role v√† faculty"""
        if role == 'STUDENT':
            bios = [
                f"Sinh vi√™n {faculty_name}, ƒëam m√™ h·ªçc h·ªèi v√† nghi√™n c·ª©u.",
                f"Y√™u th√≠ch c√¥ng ngh·ªá v√† mu·ªën ƒë√≥ng g√≥p cho s·ª± ph√°t tri·ªÉn c·ªßa ƒêBSCL.",
                f"Mong mu·ªën ·ª©ng d·ª•ng ki·∫øn th·ª©c ƒë·ªÉ gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ th·ª±c ti·ªÖn.",
                f"Quan t√¢m ƒë·∫øn c√°c ho·∫°t ƒë·ªông sinh vi√™n t·∫°i CTU."
            ]
        else:
            bios = [
                f"Gi·∫£ng vi√™n {faculty_name}, chuy√™n gi·∫£ng d·∫°y v√† nghi√™n c·ª©u.",
                f"T·∫≠p trung v√†o ·ª©ng d·ª•ng ki·∫øn th·ª©c ph·ª•c v·ª• v√πng ƒêBSCL.",
                f"ƒêam m√™ gi√°o d·ª•c v√† truy·ªÅn ƒë·∫°t ki·∫øn th·ª©c cho th·∫ø h·ªá tr·∫ª.",
                f"C√°n b·ªô {faculty_name}, h·ªó tr·ª£ ph√°t tri·ªÉn c·ªông ƒë·ªìng CTU."
            ]
        return random.choice(bios)

    def generate_posts(self, users_df, n_posts=2000):
        """T·∫°o d·ªØ li·ªáu posts theo c·∫•u tr√∫c PostEntity th·ª±c t·∫ø"""
        posts = []
        faculty_encoder = LabelEncoder()
        faculty_codes = [f['code'] for f in self.faculties]
        faculty_encoded = faculty_encoder.fit_transform(faculty_codes)

        for i in range(n_posts):
            post_id = self.generate_uuid()
            author_user = users_df.sample(1).iloc[0]
            author_info = {
                'id': author_user['id'],
                'username': author_user['username'],
                'fullName': author_user['full_name'],
                'avatarUrl': author_user['avatar_url'],
                'role': author_user['role'],
                'facultyName': 'Kh√¥ng li√™n quan h·ªçc thu·∫≠t' if random.random() < 0.1 else author_user['faculty_name']
            }

            # T·∫°o n·ªôi dung
            category = random.choice(self.post_categories)
            if category == 'other':
                author_info['facultyName'] = 'Kh√¥ng li√™n quan h·ªçc thu·∫≠t'

            title = self.generate_post_title(category, author_info['facultyName'])
            content = self.generate_post_content(category, author_user['role'])

            # Tags
            tags = self.generate_tags(category, author_info['facultyName'])

            # Media
            images = []
            videos = []
            if random.random() > 0.6:
                images = [f"https://example.com/images/{self.generate_uuid()}.jpg" for _ in range(random.randint(1, 3))]
            if random.random() > 0.9:
                videos = [f"https://example.com/videos/{self.generate_uuid()}.mp4"]

            privacy = self.determine_privacy(category, author_user['role'])

            # Stats
            view_count = random.randint(0, 1000)
            like_count = random.randint(0, min(view_count, 200))
            comment_count = random.randint(0, min(like_count, 50))
            share_count = random.randint(0, min(like_count, 30))

            created_at = datetime.now() - timedelta(
                days=random.randint(0, 180),
                hours=random.randint(0, 23),
                minutes=random.randint(0, 59)
            )

            posts.append({
                'id': post_id,
                'title': title,
                'content': content,
                'author_id': author_info['id'],
                'author_username': author_info['username'],
                'author_full_name': author_info['fullName'],
                'author_avatar_url': author_info['avatarUrl'],
                'author_role': author_info['role'],
                'author_faculty_name': author_info['facultyName'],
                'images': json.dumps(images),
                'videos': json.dumps(videos),
                'tags': json.dumps(tags),
                'category': category,
                'privacy': privacy,
                'view_count': view_count,
                'like_count': like_count,
                'comment_count': comment_count,
                'share_count': share_count,
                'created_at': created_at.isoformat(),
                'updated_at': created_at.isoformat(),
                'is_active': True,
                'post_author_faculty_encoded': faculty_encoded[faculty_codes.index('NONE' if author_info['facultyName'] == 'Kh√¥ng li√™n quan h·ªçc thu·∫≠t' else author_user['faculty_code'])] / max(faculty_encoded)
            })

        return pd.DataFrame(posts)

    def generate_post_title(self, category, faculty_name):
        """T·∫°o ti√™u ƒë·ªÅ b√†i ƒëƒÉng"""
        titles = {
            'research': [
                f"Nghi√™n c·ª©u m·ªõi trong lƒ©nh v·ª±c {faculty_name}",
                "K·∫øt qu·∫£ nghi√™n c·ª©u khoa h·ªçc m·ªõi nh·∫•t",
                "Ph∆∞∆°ng ph√°p m·ªõi trong nghi√™n c·ª©u",
                "B√°o c√°o ti·∫øn ƒë·ªô d·ª± √°n nghi√™n c·ª©u"
            ],
            'teaching': [
                f"Chia s·∫ª ph∆∞∆°ng ph√°p gi·∫£ng d·∫°y t·∫°i {faculty_name}",
                "T√†i li·ªáu h·ªçc t·∫≠p m·ªõi cho sinh vi√™n",
                "Kinh nghi·ªám gi·∫£ng d·∫°y tr·ª±c tuy·∫øn",
                "·ª®ng d·ª•ng c√¥ng ngh·ªá trong gi·∫£ng d·∫°y"
            ],
            'aquaculture': [
                "K·ªπ thu·∫≠t nu√¥i tr·ªìng th·ªßy s·∫£n b·ªÅn v·ªØng",
                "Nghi√™n c·ª©u ch·∫•t l∆∞·ª£ng n∆∞·ªõc trong ao nu√¥i",
                "·ª®ng d·ª•ng IoT trong nu√¥i t√¥m",
                "Ph√≤ng ch·ªëng b·ªánh trong nu√¥i tr·ªìng"
            ],
            'technology': [
                "·ª®ng d·ª•ng c√¥ng ngh·ªá m·ªõi t·∫°i CTU",
                "Gi·ªõi thi·ªáu c√¥ng ngh·ªá 5G trong gi√°o d·ª•c",
                "Ph√°t tri·ªÉn ·ª©ng d·ª•ng di ƒë·ªông cho sinh vi√™n",
                "Kh√°m ph√° robot trong s·∫£n xu·∫•t"
            ],
            'climate': [
                "T√°c ƒë·ªông bi·∫øn ƒë·ªïi kh√≠ h·∫≠u t·∫°i ƒêBSCL",
                "Gi·∫£i ph√°p gi·∫£m ph√°t th·∫£i kh√≠ nh√† k√≠nh",
                "D·ª± b√°o th·ªùi ti·∫øt ·ª©ng d·ª•ng AI",
                "Th√≠ch ·ª©ng v·ªõi m·ª±c n∆∞·ªõc bi·ªÉn d√¢ng"
            ],
            'student': [
                "C√¢u chuy·ªán sinh vi√™n CTU v∆∞·ª£t kh√≥",
                "H√†nh tr√¨nh kh·ªüi nghi·ªáp sinh vi√™n",
                "Tips thi cu·ªëi k·ª≥ hi·ªáu qu·∫£",
                "Ho·∫°t ƒë·ªông c√¢u l·∫°c b·ªô sinh vi√™n"
            ],
            'events': [
                "S·ª± ki·ªán giao l∆∞u vƒÉn h√≥a CTU",
                "H·ªôi th·∫£o c√¥ng ngh·ªá th√¥ng tin",
                "Ng√†y h·ªôi vi·ªác l√†m CTU",
                "Workshop k·ªπ nƒÉng m·ªÅm"
            ],
            'discussion': [
                "Th·∫£o lu·∫≠n v·ªÅ AI trong gi√°o d·ª•c",
                "C·∫£i c√°ch ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o",
                "Trao ƒë·ªïi nghi√™n c·ª©u khoa h·ªçc",
                "Gi·∫£i ph√°p ph√°t tri·ªÉn b·ªÅn v·ªØng"
            ],
            'other': [
                "Kh√°m ph√° qu√°n c√† ph√™ ƒë·∫πp ·ªü C·∫ßn Th∆°",
                "H√†nh tr√¨nh du l·ªãch mi·ªÅn T√¢y",
                "B√≠ k√≠p ch·ª•p ·∫£nh ch·ª£ n·ªïi",
                "Chuy·ªán vui ƒë·ªùi sinh vi√™n"
            ]
        }
        return random.choice(titles.get(category, titles['other']))

    def generate_post_content(self, category, author_role):
        """T·∫°o n·ªôi dung b√†i ƒëƒÉng"""
        base_content = random.choice(self.content_templates.get(category, self.content_templates['other']))
        intro = "Xin ch√†o m·ªçi ng∆∞·ªùi! " if author_role == 'STUDENT' else "T·ª´ kinh nghi·ªám gi·∫£ng d·∫°y, t√¥i mu·ªën chia s·∫ª: "
        return f"{intro}{base_content}"

    def generate_tags(self, category, faculty_name):
        """T·∫°o tags cho b√†i ƒëƒÉng"""
        common_tags = ['CTU', 'ƒêBSCL', 'gi√°od·ª•c']
        category_tags = {
            'research': ['nghi√™n c·ª©u', 'khoa h·ªçc', 'd·ª± √°n'],
            'teaching': ['gi·∫£ng d·∫°y', 'ƒë√†o t·∫°o', 'h·ªçc t·∫≠p'],
            'aquaculture': ['th·ªßy s·∫£n', 'nu√¥i tr·ªìng', 'n√¥ng nghi·ªáp'],
            'technology': ['c√¥ng ngh·ªá', 'AI', 'IoT'],
            'climate': ['kh√≠ h·∫≠u', 'm√¥i tr∆∞·ªùng', 'b·ªÅn v·ªØng'],
            'student': ['sinh vi√™n', 'h·ªçc t·∫≠p', 'c√¢u l·∫°c b·ªô'],
            'events': ['s·ª± ki·ªán', 'h·ªôi th·∫£o', 'workshop'],
            'discussion': ['th·∫£o lu·∫≠n', 'trao ƒë·ªïi', 'h·ªçc thu·∫≠t'],
            'other': ['gi·∫£i tr√≠', 'lifestyle', 'C·∫ßn Th∆°']
        }
        faculty_tag = 'none' if faculty_name == 'Kh√¥ng li√™n quan h·ªçc thu·∫≠t' else faculty_name.lower().replace(' ', '').replace('&', '')
        tags = common_tags + category_tags.get(category, []) + [faculty_tag]
        return random.sample(tags, min(len(tags), random.randint(2, 5)))

    def determine_privacy(self, category, author_role):
        """X√°c ƒë·ªãnh privacy setting"""
        if category in ['events', 'student', 'other']:
            return 'PUBLIC'
        elif author_role == 'LECTURER':
            return random.choice(['PUBLIC', 'FACULTY'])
        else:
            return random.choice(['PUBLIC', 'FRIENDS', 'FACULTY'])

    def generate_interactions(self, users_df, posts_df, n_interactions=10000):
        """T·∫°o d·ªØ li·ªáu t∆∞∆°ng t√°c d·ª±a tr√™n InteractionEntity"""
        interactions = []
        interaction_types = ['LIKE', 'SHARE', 'BOOKMARK', 'VIEW', 'COMMENT']

        for _ in range(n_interactions):
            user = users_df.sample(1).iloc[0]
            post = posts_df.sample(1).iloc[0]

            # T√≠nh x√°c su·∫•t t∆∞∆°ng t√°c
            base_prob = 0.1
            if user['faculty_code'] == post['author_faculty_name'] or post['author_faculty_name'] == 'Kh√¥ng li√™n quan h·ªçc thu·∫≠t':
                base_prob += 0.3
            if user['role'] == 'STUDENT' and post['category'] in ['student', 'events', 'other']:
                base_prob += 0.2
            elif user['role'] == 'LECTURER' and post['category'] in ['research', 'teaching', 'discussion']:
                base_prob += 0.2
            if post['privacy'] == 'PRIVATE':
                base_prob = 0.01
            elif post['privacy'] == 'FACULTY' and user['faculty_code'] != post['author_faculty_name']:
                base_prob *= 0.3

            clicked = np.random.binomial(1, min(0.8, base_prob))

            if clicked:
                time_spent = np.random.exponential(180) + 30
                scroll_depth = np.random.uniform(0.6, 1.0)
                completion_rate = np.random.uniform(0.7, 1.0)
                interaction_type = random.choice(interaction_types)
            else:
                time_spent = np.random.exponential(20) + 5
                scroll_depth = np.random.uniform(0.1, 0.4)
                completion_rate = np.random.uniform(0.0, 0.3)
                interaction_type = 'VIEW'

            interaction_time = datetime.now() - timedelta(
                days=random.randint(0, 30),
                hours=random.randint(0, 23),
                minutes=random.randint(0, 59)
            )

            interactions.append({
                'user_id': user['id'],
                'post_id': post['id'],
                'interaction_type': interaction_type,
                'clicked': clicked,
                'time_spent': time_spent,
                'scroll_depth': scroll_depth,
                'completion_rate': completion_rate,
                'interaction_time': interaction_time.isoformat(),
                'device': random.choice(['mobile', 'desktop', 'tablet']),
                'session_duration': np.random.exponential(600) + 120
            })

        return pd.DataFrame(interactions)

    def create_training_dataset(self, users_df, posts_df, interactions_df):
        """T·∫°o dataset cu·ªëi c√πng cho training model"""
        training_data = interactions_df.merge(
            users_df, left_on='user_id', right_on='id', how='left', suffixes=('', '_user')
        ).merge(
            posts_df, left_on='post_id', right_on='id', how='left', suffixes=('', '_post')
        )

        final_dataset = []

        for _, row in training_data.iterrows():
            # User features (9 chi·ªÅu)
            user_features = [
                1 if row['role'] == 'STUDENT' else 0,
                1 if row['role'] == 'LECTURER' else 0,
                1 if row['role'] == 'STAFF' else 0,
                1 if row['role'] == 'ADMIN' else 0,
                1 if row['is_profile_completed'] else 0,
                pd.to_datetime(row['interaction_time']).hour / 24.0,
                pd.to_datetime(row['interaction_time']).weekday() / 7.0,
                row['user_faculty_encoded']
            ]

            # Post features (13 chi·ªÅu)
            post_features = [
                hash(row['category']) % 10 / 10.0,
                1 if row['privacy'] == 'PUBLIC' else 0,
                1 if row['privacy'] == 'FRIENDS' else 0,
                1 if row['privacy'] == 'FACULTY' else 0,
                1 if row['privacy'] == 'PRIVATE' else 0,
                row['view_count'] / 1000.0,
                row['like_count'] / 200.0,
                row['comment_count'] / 50.0,
                row['share_count'] / 30.0,
                len(row['content']) / 1000.0,
                len(json.loads(row['tags'])) / 10.0,
                1 if json.loads(row['images']) else 0,
                row['post_author_faculty_encoded']
            ]

            # Interaction features (8 chi·ªÅu)
            interaction_features = [
                row['time_spent'] / 600.0,
                row['scroll_depth'],
                row['completion_rate'],
                row['session_duration'] / 1800.0,
                1 if row['faculty_code'] == row['author_faculty_name'] or row['author_faculty_name'] == 'Kh√¥ng li√™n quan h·ªçc thu·∫≠t' else 0,
                1 if row['interaction_type'] == 'LIKE' else 0,
                1 if row['interaction_type'] == 'COMMENT' else 0,
                1 if row['interaction_type'] == 'SHARE' else 0
            ]

            final_dataset.append({
                'user_id': row['user_id'],
                'post_id': row['post_id'],
                'user_features': user_features,
                'post_features': post_features,
                'interaction_features': interaction_features,
                'label': row['clicked'],
                'timestamp': row['interaction_time'],
                'user_role': row['role'],
                'post_category': row['category'],
                'user_faculty': row['faculty_name'],
                'post_author_faculty': row['author_faculty_name'],
                'user_faculty_encoded': row['user_faculty_encoded'],
                'post_author_faculty_encoded': row['post_author_faculty_encoded']
            })

        return pd.DataFrame(final_dataset)

    def generate_full_dataset(self, n_users=10, n_posts=20, n_interactions=100, save_path='data/'):
        """T·∫°o dataset ho√†n ch·ªânh cho CTU Connect"""
        print("üöÄ B·∫Øt ƒë·∫ßu t·∫°o dataset cho CTU Connect...")

        os.makedirs(save_path, exist_ok=True)

        print("üë• T·∫°o d·ªØ li·ªáu users...")
        users_df = self.generate_users(n_users)

        print("üìÑ T·∫°o d·ªØ li·ªáu posts...")
        posts_df = self.generate_posts(users_df, n_posts)

        print("ü§ù T·∫°o d·ªØ li·ªáu interactions...")
        interactions_df = self.generate_interactions(users_df, posts_df, n_interactions)

        print("üìä T·∫°o training dataset...")
        training_df = self.create_training_dataset(users_df, posts_df, interactions_df)

        # Save datasets
        users_df.to_csv(f'{save_path}/ctu_connect_users.csv', index=False)
        posts_df.to_csv(f'{save_path}/ctu_connect_posts.csv', index=False)
        interactions_df.to_csv(f'{save_path}/ctu_connect_interactions.csv', index=False)
        training_df.to_csv(f'{save_path}/ctu_connect_training.csv', index=False)

        # Save metadata
        metadata = {
            'dataset_info': {
                'name': 'CTU Connect Social Network Dataset',
                'description': 'Dataset for CTU Connect recommendation system',
                'faculties': self.faculties,
                'roles': self.roles,
                'post_categories': self.post_categories,
                'n_users': len(users_df),
                'n_posts': len(posts_df),
                'n_interactions': len(interactions_df),
                'created_date': datetime.now().isoformat()
            }
        }

        with open(f'{save_path}/ctu_connect_metadata.json', 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        print(f"\n‚úÖ Dataset CTU Connect ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
        print(f"üìÅ V·ªã tr√≠: {save_path}")
        print(f"üë• S·ªë l∆∞·ª£ng users: {len(users_df)}")
        print(f"üìÑ S·ªë l∆∞·ª£ng posts: {len(posts_df)}")
        print(f"ü§ù S·ªë l∆∞·ª£ng interactions: {len(interactions_df)}")
        print(f"üìä Training dataset: {len(training_df)} samples")

        return {
            'users': users_df,
            'posts': posts_df,
            'interactions': interactions_df,
            'training': training_df,
            'metadata': metadata
        }

if __name__ == "__main__":
    generator = CTUConnectDataGenerator(seed=42)
    dataset = generator.generate_full_dataset(
        n_users=10,
        n_posts=150,
        n_interactions=80,
        save_path='data/ctu_connect/'
    )