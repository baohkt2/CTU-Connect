import pandas as pd
import numpy as np
import random
from datetime import datetime, timedelta
import json
import os
import uuid


class CTUConnectDataGenerator:
    """T·∫°o dataset m·∫´u cho h·ªá th·ªëng CTU Connect d·ª±a tr√™n c·∫•u tr√∫c th·ª±c t·∫ø"""

    def __init__(self, seed=42):
        random.seed(seed)
        np.random.seed(seed)

        # Danh s√°ch khoa th·ª±c t·∫ø t·∫°i CTU (d·ª±a tr√™n FacultyEntity)
        self.faculties = [
            {'code': 'FIT', 'name': 'Khoa C√¥ng ngh·ªá Th√¥ng tin & Truy·ªÅn th√¥ng', 'college': 'CTU'},
            {'code': 'AGR', 'name': 'Khoa N√¥ng nghi·ªáp', 'college': 'CTU'},
            {'code': 'ENG', 'name': 'Khoa K·ªπ thu·∫≠t C√¥ng ngh·ªá', 'college': 'CTU'},
            {'code': 'ECO', 'name': 'Khoa Kinh t·∫ø', 'college': 'CTU'},
            {'code': 'EDU', 'name': 'Khoa S∆∞ ph·∫°m', 'college': 'CTU'},
            {'code': 'MED', 'name': 'Khoa Y D∆∞·ª£c', 'college': 'CTU'},
            {'code': 'SCI', 'name': 'Khoa Khoa h·ªçc T·ª± nhi√™n', 'college': 'CTU'},
            {'code': 'ENV', 'name': 'Khoa M√¥i tr∆∞·ªùng & T√†i nguy√™n Thi√™n nhi√™n', 'college': 'CTU'},
            {'code': 'AQU', 'name': 'Khoa Th·ªßy s·∫£n', 'college': 'CTU'},
            {'code': 'LAW', 'name': 'Khoa Lu·∫≠t', 'college': 'CTU'},
            {'code': 'FL', 'name': 'Khoa Ngo·∫°i ng·ªØ', 'college': 'CTU'},
            {'code': 'HUM', 'name': 'Khoa Nh√¢n vƒÉn & X√£ h·ªôi', 'college': 'CTU'}
        ]

        # Danh s√°ch ng√†nh h·ªçc theo t·ª´ng khoa (d·ª±a tr√™n MajorEntity)
        self.majors_by_faculty = {
            'FIT': [
                {'code': 'IT', 'name': 'C√¥ng ngh·ªá Th√¥ng tin'},
                {'code': 'SE', 'name': 'K·ªπ thu·∫≠t Ph·∫ßn m·ªÅm'},
                {'code': 'IS', 'name': 'H·ªá th·ªëng Th√¥ng tin'},
                {'code': 'AI', 'name': 'Tr√≠ tu·ªá Nh√¢n t·∫°o'},
                {'code': 'CS', 'name': 'Khoa h·ªçc M√°y t√≠nh'}
            ],
            'AGR': [
                {'code': 'AGRO', 'name': 'N√¥ng h·ªçc'},
                {'code': 'PLANT', 'name': 'B·∫£o v·ªá Th·ª±c v·∫≠t'},
                {'code': 'SOIL', 'name': 'Khoa h·ªçc ƒê·∫•t'},
                {'code': 'CROP', 'name': 'Khoa h·ªçc C√¢y tr·ªìng'}
            ],
            'ENG': [
                {'code': 'CE', 'name': 'K·ªπ thu·∫≠t X√¢y d·ª±ng'},
                {'code': 'ME', 'name': 'K·ªπ thu·∫≠t C∆° kh√≠'},
                {'code': 'EE', 'name': 'K·ªπ thu·∫≠t ƒêi·ªán'},
                {'code': 'ChE', 'name': 'K·ªπ thu·∫≠t H√≥a h·ªçc'}
            ],
            'ECO': [
                {'code': 'ECON', 'name': 'Kinh t·∫ø'},
                {'code': 'BIZ', 'name': 'Qu·∫£n tr·ªã Kinh doanh'},
                {'code': 'ACC', 'name': 'K·∫ø to√°n'},
                {'code': 'FIN', 'name': 'T√†i ch√≠nh Ng√¢n h√†ng'}
            ],
            'EDU': [
                {'code': 'MATH_EDU', 'name': 'S∆∞ ph·∫°m To√°n'},
                {'code': 'PHYS_EDU', 'name': 'S∆∞ ph·∫°m V·∫≠t l√Ω'},
                {'code': 'CHEM_EDU', 'name': 'S∆∞ ph·∫°m H√≥a h·ªçc'},
                {'code': 'BIO_EDU', 'name': 'S∆∞ ph·∫°m Sinh h·ªçc'}
            ]
        }

        # Vai tr√≤ ng∆∞·ªùi d√πng (d·ª±a tr√™n Role enum)
        self.roles = ['STUDENT', 'LECTURER', 'STAFF', 'ADMIN', 'RESEARCHER']

        # Tr√¨nh ƒë·ªô h·ªçc v·∫•n (d·ª±a tr√™n DegreeEntity)
        self.degrees = [
            {'code': 'HS', 'name': 'T·ªët nghi·ªáp THPT'},
            {'code': 'BACHELOR', 'name': 'C·ª≠ nh√¢n'},
            {'code': 'MASTER', 'name': 'Th·∫°c sƒ©'},
            {'code': 'PHD', 'name': 'Ti·∫øn sƒ©'},
            {'code': 'ASSOC_PROF', 'name': 'Ph√≥ Gi√°o s∆∞'},
            {'code': 'PROF', 'name': 'Gi√°o s∆∞'}
        ]

        # Ch·ª©c v·ª• (d·ª±a tr√™n PositionEntity)
        self.positions = [
            {'code': 'STUDENT', 'name': 'Sinh vi√™n'},
            {'code': 'LECTURER', 'name': 'Gi·∫£ng vi√™n'},
            {'code': 'SENIOR_LECTURER', 'name': 'Gi·∫£ng vi√™n ch√≠nh'},
            {'code': 'ASSOC_PROF', 'name': 'Ph√≥ Gi√°o s∆∞'},
            {'code': 'PROF', 'name': 'Gi√°o s∆∞'},
            {'code': 'HEAD_DEPT', 'name': 'Tr∆∞·ªüng b·ªô m√¥n'},
            {'code': 'DEAN', 'name': 'Tr∆∞·ªüng khoa'},
            {'code': 'ADMIN_STAFF', 'name': 'C√°n b·ªô h√†nh ch√≠nh'}
        ]

        # Kh√≥a h·ªçc (d·ª±a tr√™n BatchEntity)
        self.batches = [
            {'id': f'K{year}', 'year': year}
            for year in range(2019, 2025)
        ]

        # Gi·ªõi t√≠nh (d·ª±a tr√™n GenderEntity)
        self.genders = [
            {'id': 'MALE', 'name': 'Nam'},
            {'id': 'FEMALE', 'name': 'N·ªØ'},
            {'id': 'OTHER', 'name': 'Kh√°c'}
        ]

        # Danh m·ª•c b√†i ƒëƒÉng (categories cho PostEntity)
        self.post_categories = [
            'ACADEMIC', 'RESEARCH', 'ANNOUNCEMENT', 'EVENT', 'SOCIAL',
            'CAREER', 'SCHOLARSHIP', 'COLLABORATION', 'DISCUSSION', 'NEWS'
        ]

        # Ch·∫ø ƒë·ªô ri√™ng t∆∞ (privacy cho PostEntity)
        self.privacy_settings = ['PUBLIC', 'FRIENDS', 'FACULTY', 'PRIVATE']

        # Content templates cho t·ª´ng category
        self.content_templates = {
            'ACADEMIC': [
                "Nghi√™n c·ª©u m·ªõi v·ªÅ ·ª©ng d·ª•ng AI trong n√¥ng nghi·ªáp th√¥ng minh t·∫°i v√πng ƒêBSCL ƒëang cho th·∫•y k·∫øt qu·∫£ kh·∫£ quan.",
                "B√°o c√°o k·∫øt qu·∫£ th√≠ nghi·ªám v·ªÅ gi·ªëng l√∫a ch·ªëng m·∫∑n ph√π h·ª£p v·ªõi ƒëi·ªÅu ki·ªán bi·∫øn ƒë·ªïi kh√≠ h·∫≠u.",
                "Ph∆∞∆°ng ph√°p m·ªõi trong x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn √°p d·ª•ng cho nghi√™n c·ª©u n√¥ng nghi·ªáp.",
                "·ª®ng d·ª•ng IoT trong qu·∫£n l√Ω t∆∞·ªõi ti√™u th√¥ng minh cho c√¢y l√∫a."
            ],
            'RESEARCH': [
                "D·ª± √°n nghi√™n c·ª©u v·ªÅ blockchain trong qu·∫£n l√Ω chu·ªói cung ·ª©ng n√¥ng s·∫£n ƒëang ƒë∆∞·ª£c tri·ªÉn khai.",
                "K·∫øt qu·∫£ nghi√™n c·ª©u v·ªÅ t√°c ƒë·ªông c·ªßa bi·∫øn ƒë·ªïi kh√≠ h·∫≠u ƒë·∫øn nƒÉng su·∫•t l√∫a ƒêBSCL.",
                "Nghi√™n c·ª©u ·ª©ng d·ª•ng machine learning trong d·ª± b√°o th·ªùi ti·∫øt n√¥ng nghi·ªáp.",
                "Ph√°t tri·ªÉn h·ªá th·ªëng gi√°m s√°t ch·∫•t l∆∞·ª£ng n∆∞·ªõc nu√¥i tr·ªìng th·ªßy s·∫£n b·∫±ng c·∫£m bi·∫øn IoT."
            ],
            'ANNOUNCEMENT': [
                "Th√¥ng b√°o t·ªï ch·ª©c h·ªôi th·∫£o khoa h·ªçc qu·ªëc t·∫ø v·ªÅ ph√°t tri·ªÉn b·ªÅn v·ªØng ƒêBSCL.",
                "Th√¥ng b√°o tuy·ªÉn sinh vi√™n tham gia d·ª± √°n nghi√™n c·ª©u khoa h·ªçc c·∫•p tr∆∞·ªùng.",
                "Th√¥ng b√°o l·ªãch b·∫£o v·ªá lu·∫≠n vƒÉn th·∫°c sƒ© h·ªçc k·ª≥ 2 nƒÉm 2024.",
                "Th√¥ng b√°o m·ªü ƒëƒÉng k√Ω h·ªçc b·ªïng Erasmus+ cho sinh vi√™n CTU."
            ],
            'EVENT': [
                "S·ª± ki·ªán giao l∆∞u vƒÉn h√≥a gi·ªØa sinh vi√™n qu·ªëc t·∫ø v√† sinh vi√™n CTU.",
                "Workshop v·ªÅ k·ªπ nƒÉng nghi√™n c·ª©u khoa h·ªçc cho sinh vi√™n nƒÉm cu·ªëi.",
                "H·ªôi th·∫£o v·ªÅ c∆° h·ªôi vi·ªác l√†m trong lƒ©nh v·ª±c c√¥ng ngh·ªá th√¥ng tin.",
                "Ng√†y h·ªôi kh·ªüi nghi·ªáp CTU 2024 - K·∫øt n·ªëi √Ω t∆∞·ªüng, kh·ªüi t·∫°o t∆∞∆°ng lai."
            ]
        }

    def generate_uuid(self):
        """T·∫°o UUID theo format c·ªßa h·ªá th·ªëng"""
        return str(uuid.uuid4())

    def generate_users(self, n_users=100):
        """T·∫°o d·ªØ li·ªáu users theo c·∫•u tr√∫c UserEntity th·ª±c t·∫ø"""
        users = []

        for i in range(n_users):
            user_id = self.generate_uuid()

            # Ph√¢n b·ªë role
            if i < n_users * 0.7:  # 70% sinh vi√™n
                role = 'STUDENT'
            elif i < n_users * 0.9:  # 20% gi·∫£ng vi√™n
                role = 'LECTURER'
            elif i < n_users * 0.95:  # 5% nghi√™n c·ª©u vi√™n
                role = 'RESEARCHER'
            else:  # 5% c√°n b·ªô/admin
                role = random.choice(['STAFF', 'ADMIN'])

            # T·∫°o th√¥ng tin c∆° b·∫£n
            username = f"user{i+1:04d}"
            email = f"{username}@ctu.edu.vn"
            full_name = self.generate_vietnamese_name()

            # Ch·ªçn faculty v√† major
            faculty = random.choice(self.faculties)
            major_list = self.majors_by_faculty.get(faculty['code'], [])
            major = random.choice(major_list) if major_list else None

            # Th√¥ng tin h·ªçc t·∫≠p/c√¥ng vi·ªác
            if role == 'STUDENT':
                student_id = f"B{random.randint(1900000, 2199999)}"
                staff_code = None
                batch = random.choice(self.batches)
                degree = random.choice([d for d in self.degrees if d['code'] in ['HS', 'BACHELOR']])
                position = next(p for p in self.positions if p['code'] == 'STUDENT')
            else:
                student_id = None
                staff_code = f"CB{random.randint(10000, 99999)}"
                batch = None
                degree = random.choice([d for d in self.degrees if d['code'] in ['MASTER', 'PHD', 'ASSOC_PROF', 'PROF']])
                position = random.choice([p for p in self.positions if p['code'] != 'STUDENT'])

            gender = random.choice(self.genders)

            # Profile completion v√† th√¥ng tin b·ªï sung
            is_profile_completed = random.choice([True, False])
            bio = self.generate_bio(role, faculty['name']) if is_profile_completed else None
            avatar_url = f"https://example.com/avatars/{user_id}.jpg" if random.random() > 0.3 else None

            users.append({
                'id': user_id,
                'email': email,
                'username': username,
                'full_name': full_name,
                'role': role,
                'bio': bio,
                'is_profile_completed': is_profile_completed,
                'avatar_url': avatar_url,
                'background_url': None,
                'student_id': student_id,
                'staff_code': staff_code,
                'is_active': True,
                'created_at': (datetime.now() - timedelta(days=random.randint(30, 1095))).isoformat(),
                'updated_at': datetime.now().isoformat(),
                # Relations
                'faculty_code': faculty['code'],
                'faculty_name': faculty['name'],
                'major_code': major['code'] if major else None,
                'major_name': major['name'] if major else None,
                'batch_id': batch['id'] if batch else None,
                'batch_year': batch['year'] if batch else None,
                'gender_id': gender['id'],
                'gender_name': gender['name'],
                'degree_code': degree['code'],
                'degree_name': degree['name'],
                'position_code': position['code'],
                'position_name': position['name'],
                'college_name': 'ƒê·∫°i h·ªçc C·∫ßn Th∆°'
            })

        return pd.DataFrame(users)

    def generate_vietnamese_name(self):
        """T·∫°o t√™n ti·∫øng Vi·ªát ng·∫´u nhi√™n"""
        first_names = [
            'Nguy·ªÖn', 'Tr·∫ßn', 'L√™', 'Ph·∫°m', 'Hu·ª≥nh', 'Ho√†ng', 'Phan', 'V≈©', 'V√µ', 'ƒê·∫∑ng',
            'B√πi', 'ƒê·ªó', 'H·ªì', 'Ng√¥', 'D∆∞∆°ng', 'L√Ω', 'L∆∞∆°ng', 'Tr·ªãnh', 'ƒêinh', 'T√¥'
        ]

        middle_names = ['VƒÉn', 'Th·ªã', 'H·ªØu', 'Minh', 'Thanh', 'Ho√†ng', 'Qu·ªëc', 'ƒê·ª©c', 'H·ªìng', 'Thu']

        last_names_male = [
            'Nam', 'H√πng', 'D≈©ng', 'Tu·∫•n', 'Hi·∫øu', 'Phong', 'Minh', 'Quang', 'ƒê·ª©c', 'B√¨nh',
            'Long', 'Th√†nh', 'Khang', 'H·∫£i', 'T√¢n', 'Vi·ªát', 'S∆°n', 'Khoa', 'T√πng', 'Ki√™n'
        ]

        last_names_female = [
            'Linh', 'Nga', 'H∆∞∆°ng', 'Lan', 'Mai', 'Ch√¢u', 'Th·∫£o', 'Hoa', 'Y·∫øn', 'Nhung',
            'Trang', 'Giang', 'Ph∆∞∆°ng', 'Oanh', 'Xu√¢n', 'Thu', 'H√†', 'Di·ªáu', 'Kh√°nh', 'My'
        ]

        first_name = random.choice(first_names)
        middle_name = random.choice(middle_names)

        if middle_name == 'Th·ªã':
            last_name = random.choice(last_names_female)
        else:
            last_name = random.choice(last_names_male + last_names_female)

        return f"{first_name} {middle_name} {last_name}"

    def generate_bio(self, role, faculty_name):
        """T·∫°o bio ph√π h·ª£p v·ªõi role v√† faculty"""
        if role == 'STUDENT':
            bios = [
                f"Sinh vi√™n {faculty_name}, ƒëam m√™ h·ªçc h·ªèi v√† nghi√™n c·ª©u.",
                "Y√™u th√≠ch c√¥ng ngh·ªá v√† mu·ªën ƒë√≥ng g√≥p cho s·ª± ph√°t tri·ªÉn c·ªßa ƒêBSCL.",
                "Mong mu·ªën ·ª©ng d·ª•ng ki·∫øn th·ª©c ƒë·ªÉ gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ th·ª±c ti·ªÖn.",
                "Quan t√¢m ƒë·∫øn nghi√™n c·ª©u khoa h·ªçc v√† ph√°t tri·ªÉn b·ªÅn v·ªØng."
            ]
        else:
            bios = [
                f"Gi·∫£ng vi√™n {faculty_name}, chuy√™n nghi√™n c·ª©u v√† gi·∫£ng d·∫°y.",
                "T·∫≠p trung v√†o nghi√™n c·ª©u ·ª©ng d·ª•ng ph·ª•c v·ª• ph√°t tri·ªÉn v√πng ƒêBSCL.",
                "ƒêam m√™ gi√°o d·ª•c v√† truy·ªÅn ƒë·∫°t ki·∫øn th·ª©c cho th·∫ø h·ªá tr·∫ª.",
                "Nghi√™n c·ª©u vi√™n v·ªõi nhi·ªÅu nƒÉm kinh nghi·ªám trong lƒ©nh v·ª±c chuy√™n m√¥n."
            ]

        return random.choice(bios)

    def generate_posts(self, users_df, n_posts=2000):
        """T·∫°o d·ªØ li·ªáu posts theo c·∫•u tr√∫c PostEntity th·ª±c t·∫ø"""
        posts = []

        for i in range(n_posts):
            post_id = self.generate_uuid()

            # Ch·ªçn author t·ª´ users_df
            author_user = users_df.sample(1).iloc[0]
            author_info = {
                'id': author_user['id'],
                'username': author_user['username'],
                'fullName': author_user['full_name'],
                'avatarUrl': author_user['avatar_url'],
                'role': author_user['role'],
                'facultyName': author_user['faculty_name']
            }

            # T·∫°o n·ªôi dung
            category = random.choice(self.post_categories)
            title = self.generate_post_title(category, author_user['faculty_name'])
            content = self.generate_post_content(category, author_user['role'])

            # Tags
            tags = self.generate_tags(category, author_user['faculty_name'])

            # Media
            images = []
            videos = []
            if random.random() > 0.6:  # 40% c√≥ h√¨nh ·∫£nh
                images = [f"https://example.com/images/{self.generate_uuid()}.jpg"
                         for _ in range(random.randint(1, 3))]
            if random.random() > 0.9:  # 10% c√≥ video
                videos = [f"https://example.com/videos/{self.generate_uuid()}.mp4"]

            privacy = self.determine_privacy(category, author_user['role'])

            # Stats
            view_count = random.randint(0, 1000)
            like_count = random.randint(0, min(view_count, 200))
            comment_count = random.randint(0, min(like_count, 50))
            share_count = random.randint(0, min(like_count, 30))

            created_at = datetime.now() - timedelta(
                days=random.randint(0, 180),
                hours=random.randint(0, 23),
                minutes=random.randint(0, 59)
            )

            posts.append({
                'id': post_id,
                'title': title,
                'content': content,
                'author_id': author_info['id'],
                'author_username': author_info['username'],
                'author_full_name': author_info['fullName'],
                'author_avatar_url': author_info['avatarUrl'],
                'author_role': author_info['role'],
                'author_faculty_name': author_info['facultyName'],
                'images': json.dumps(images),
                'videos': json.dumps(videos),
                'tags': json.dumps(tags),
                'category': category,
                'privacy': privacy,
                'view_count': view_count,
                'like_count': like_count,
                'comment_count': comment_count,
                'share_count': share_count,
                'created_at': created_at.isoformat(),
                'updated_at': created_at.isoformat(),
                'is_active': True
            })

        return pd.DataFrame(posts)

    def generate_post_title(self, category, faculty_name):
        """T·∫°o ti√™u ƒë·ªÅ b√†i ƒëƒÉng"""
        titles = {
            'ACADEMIC': [
                f"Nghi√™n c·ª©u m·ªõi trong lƒ©nh v·ª±c {faculty_name}",
                "K·∫øt qu·∫£ nghi√™n c·ª©u khoa h·ªçc m·ªõi nh·∫•t",
                "Ph∆∞∆°ng ph√°p m·ªõi trong nghi√™n c·ª©u",
                "B√°o c√°o ti·∫øn ƒë·ªô d·ª± √°n nghi√™n c·ª©u"
            ],
            'RESEARCH': [
                "D·ª± √°n nghi√™n c·ª©u c·∫ßn tuy·ªÉn th√†nh vi√™n",
                "C∆° h·ªôi h·ª£p t√°c nghi√™n c·ª©u",
                "K·∫øt qu·∫£ th√≠ nghi·ªám th√∫ v·ªã",
                "T√¨m ki·∫øm ƒë·ªëi t√°c nghi√™n c·ª©u"
            ],
            'ANNOUNCEMENT': [
                "Th√¥ng b√°o quan tr·ªçng t·ª´ khoa",
                "Th√¥ng b√°o tuy·ªÉn sinh",
                "Th√¥ng b√°o l·ªãch thi",
                "Th√¥ng b√°o h·ªçc b·ªïng"
            ],
            'EVENT': [
                "S·ª± ki·ªán s·∫Øp di·ªÖn ra t·∫°i CTU",
                "Workshop chuy√™n m√¥n",
                "H·ªôi th·∫£o khoa h·ªçc",
                "Giao l∆∞u vƒÉn h√≥a"
            ]
        }

        return random.choice(titles.get(category, titles['ACADEMIC']))

    def generate_post_content(self, category, author_role):
        """T·∫°o n·ªôi dung b√†i ƒëƒÉng"""
        base_content = random.choice(self.content_templates.get(category, self.content_templates['ACADEMIC']))

        if author_role in ['LECTURER', 'RESEARCHER']:
            intro = "T·ª´ kinh nghi·ªám nghi√™n c·ª©u v√† gi·∫£ng d·∫°y, t√¥i mu·ªën chia s·∫ª: "
        else:
            intro = "Xin ch√†o m·ªçi ng∆∞·ªùi! "

        return f"{intro}{base_content}"

    def generate_tags(self, category, faculty_name):
        """T·∫°o tags cho b√†i ƒëƒÉng"""
        common_tags = ['CTU', 'ƒêBSCL', 'nghi√™nc·ª©u', 'gi√°od·ª•c']
        category_tags = {
            'ACADEMIC': ['khoa h·ªçc', 'academic', 'research'],
            'RESEARCH': ['nghi√™n c·ª©u', 'd·ª± √°n', 'h·ª£p t√°c'],
            'ANNOUNCEMENT': ['th√¥ng b√°o', 'quan tr·ªçng'],
            'EVENT': ['s·ª± ki·ªán', 'workshop', 'h·ªôi th·∫£o']
        }

        faculty_tag = faculty_name.lower().replace(' ', '').replace('&', '')

        tags = common_tags + category_tags.get(category, []) + [faculty_tag]
        return random.sample(tags, min(len(tags), random.randint(2, 5)))

    def determine_privacy(self, category, author_role):
        """X√°c ƒë·ªãnh privacy setting"""
        if category in ['ANNOUNCEMENT', 'EVENT']:
            return 'PUBLIC'
        elif author_role in ['LECTURER', 'RESEARCHER']:
            return random.choice(['PUBLIC', 'FACULTY'])
        else:
            return random.choice(['PUBLIC', 'FRIENDS', 'FACULTY'])

    def generate_interactions(self, users_df, posts_df, n_interactions=10000):
        """T·∫°o d·ªØ li·ªáu t∆∞∆°ng t√°c d·ª±a tr√™n InteractionEntity"""
        interactions = []

        for _ in range(n_interactions):
            user = users_df.sample(1).iloc[0]
            post = posts_df.sample(1).iloc[0]

            # T√≠nh x√°c su·∫•t t∆∞∆°ng t√°c d·ª±a tr√™n:
            # 1. C√πng faculty
            # 2. Category ph√π h·ª£p v·ªõi role
            # 3. Privacy setting

            base_prob = 0.1

            # C√πng faculty tƒÉng x√°c su·∫•t
            if user['faculty_code'] == post['author_faculty_name']:
                base_prob += 0.3

            # Role ph√π h·ª£p v·ªõi category
            if user['role'] == 'STUDENT' and post['category'] in ['EVENT', 'ANNOUNCEMENT']:
                base_prob += 0.2
            elif user['role'] in ['LECTURER', 'RESEARCHER'] and post['category'] in ['ACADEMIC', 'RESEARCH']:
                base_prob += 0.2

            # Privacy check
            if post['privacy'] == 'PRIVATE':
                base_prob = 0.01
            elif post['privacy'] == 'FACULTY' and user['faculty_code'] != post['author_faculty_name']:
                base_prob *= 0.3

            clicked = np.random.binomial(1, min(0.8, base_prob))

            if clicked:
                time_spent = np.random.exponential(180) + 30  # seconds
                scroll_depth = np.random.uniform(0.6, 1.0)
                completion_rate = np.random.uniform(0.7, 1.0)
                interaction_type = random.choice(['LIKE', 'COMMENT', 'SHARE', 'VIEW'])
            else:
                time_spent = np.random.exponential(20) + 5
                scroll_depth = np.random.uniform(0.1, 0.4)
                completion_rate = np.random.uniform(0.0, 0.3)
                interaction_type = 'VIEW'

            interaction_time = datetime.now() - timedelta(
                days=random.randint(0, 30),
                hours=random.randint(0, 23),
                minutes=random.randint(0, 59)
            )

            interactions.append({
                'user_id': user['id'],
                'post_id': post['id'],
                'interaction_type': interaction_type,
                'clicked': clicked,
                'time_spent': time_spent,
                'scroll_depth': scroll_depth,
                'completion_rate': completion_rate,
                'interaction_time': interaction_time.isoformat(),
                'device': random.choice(['mobile', 'desktop', 'tablet']),
                'session_duration': np.random.exponential(600) + 120
            })

        return pd.DataFrame(interactions)

    def create_training_dataset(self, users_df, posts_df, interactions_df):
        """T·∫°o dataset cu·ªëi c√πng cho training model"""

        # Merge all data
        training_data = interactions_df.merge(
            users_df, left_on='user_id', right_on='id', how='left', suffixes=('', '_user')
        ).merge(
            posts_df, left_on='post_id', right_on='id', how='left', suffixes=('', '_post')
        )

        final_dataset = []

        for _, row in training_data.iterrows():
            # User features (chu·∫©n h√≥a)
            user_features = [
                1 if row['role'] == 'STUDENT' else 0,
                1 if row['role'] == 'LECTURER' else 0,
                1 if row['role'] == 'RESEARCHER' else 0,
                1 if row['role'] == 'STAFF' else 0,
                1 if row['role'] == 'ADMIN' else 0,
                hash(row['faculty_code']) % 20 / 20.0,  # faculty encoding
                hash(row['major_code']) % 30 / 30.0 if row['major_code'] else 0,  # major encoding
                1 if row['gender_id'] == 'MALE' else 0,
                1 if row['gender_id'] == 'FEMALE' else 0,
                1 if row['is_profile_completed'] else 0,
                hash(row['degree_code']) % 10 / 10.0,  # degree encoding
                hash(row['position_code']) % 15 / 15.0,  # position encoding
                # Time features
                pd.to_datetime(row['interaction_time']).hour / 24.0,
                pd.to_datetime(row['interaction_time']).weekday() / 7.0,
                # Device features
                1 if row['device'] == 'mobile' else 0,
                1 if row['device'] == 'desktop' else 0,
                1 if row['device'] == 'tablet' else 0
            ]

            # Post features
            post_features = [
                hash(row['category']) % 10 / 10.0,  # category encoding
                1 if row['privacy'] == 'PUBLIC' else 0,
                1 if row['privacy'] == 'FRIENDS' else 0,
                1 if row['privacy'] == 'FACULTY' else 0,
                1 if row['privacy'] == 'PRIVATE' else 0,
                row['view_count'] / 1000.0,  # normalized
                row['like_count'] / 200.0,   # normalized
                row['comment_count'] / 50.0,  # normalized
                row['share_count'] / 30.0,   # normalized
                len(row['content']) / 1000.0,  # content length normalized
                len(json.loads(row['tags'])) / 10.0,  # tags count normalized
                1 if json.loads(row['images']) else 0,  # has images
                1 if json.loads(row['videos']) else 0,  # has videos
                (datetime.now() - pd.to_datetime(row['created_at'])).days / 180.0  # days since created
            ]

            # Interaction features
            interaction_features = [
                row['time_spent'] / 600.0,  # normalized
                row['scroll_depth'],
                row['completion_rate'],
                row['session_duration'] / 1800.0,  # normalized
                1 if row['faculty_code'] == row['author_faculty_name'] else 0,  # same faculty
                1 if row['interaction_type'] == 'LIKE' else 0,
                1 if row['interaction_type'] == 'COMMENT' else 0,
                1 if row['interaction_type'] == 'SHARE' else 0
            ]

            final_dataset.append({
                'user_id': row['user_id'],
                'post_id': row['post_id'],
                'user_features': user_features,
                'post_features': post_features,
                'interaction_features': interaction_features,
                'label': row['clicked'],
                'timestamp': row['interaction_time'],
                # Metadata
                'user_role': row['role'],
                'post_category': row['category'],
                'user_faculty': row['faculty_name'],
                'post_author_faculty': row['author_faculty_name']
            })

        return pd.DataFrame(final_dataset)

    def generate_full_dataset(self, n_users=10, n_posts=20, n_interactions=100, save_path='data/'):
        """T·∫°o dataset ho√†n ch·ªânh cho CTU Connect"""

        print("üöÄ B·∫Øt ƒë·∫ßu t·∫°o dataset cho CTU Connect...")

        # Create directory
        os.makedirs(save_path, exist_ok=True)

        # Generate data
        print("üë• T·∫°o d·ªØ li·ªáu users...")
        users_df = self.generate_users(n_users)

        print("üìÑ T·∫°o d·ªØ li·ªáu posts...")
        posts_df = self.generate_posts(users_df, n_posts)

        print("ü§ù T·∫°o d·ªØ li·ªáu interactions...")
        interactions_df = self.generate_interactions(users_df, posts_df, n_interactions)

        print("üìä T·∫°o training dataset...")
        training_df = self.create_training_dataset(users_df, posts_df, interactions_df)

        # Save datasets
        users_df.to_csv(f'{save_path}/ctu_connect_users.csv', index=False)
        posts_df.to_csv(f'{save_path}/ctu_connect_posts.csv', index=False)
        interactions_df.to_csv(f'{save_path}/ctu_connect_interactions.csv', index=False)
        training_df.to_csv(f'{save_path}/ctu_connect_training.csv', index=False)

        # Save metadata
        metadata = {
            'dataset_info': {
                'name': 'CTU Connect Social Network Dataset',
                'description': 'Dataset for CTU Connect recommendation system',
                'faculties': self.faculties,
                'roles': self.roles,
                'post_categories': self.post_categories,
                'n_users': len(users_df),
                'n_posts': len(posts_df),
                'n_interactions': len(interactions_df),
                'created_date': datetime.now().isoformat()
            }
        }

        with open(f'{save_path}/ctu_connect_metadata.json', 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        print(f"\n‚úÖ Dataset CTU Connect ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
        print(f"üìÅ V·ªã tr√≠: {save_path}")
        print(f"üë• S·ªë l∆∞·ª£ng users: {len(users_df)}")
        print(f"üìÑ S·ªë l∆∞·ª£ng posts: {len(posts_df)}")
        print(f"ü§ù S·ªë l∆∞·ª£ng interactions: {len(interactions_df)}")
        print(f"üìä Training dataset: {len(training_df)} samples")

        return {
            'users': users_df,
            'posts': posts_df,
            'interactions': interactions_df,
            'training': training_df,
            'metadata': metadata
        }


# Example usage
if __name__ == "__main__":
    generator = CTUConnectDataGenerator(seed=42)

    dataset = generator.generate_full_dataset(
        n_users=10,
        n_posts=150,
        n_interactions=80,
        save_path='data/ctu_connect/'
    )
